{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20f7afdb-ba76-44d0-b8b1-127e62ca1184",
   "metadata": {},
   "source": [
    "# Кореф"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8e2e09b-5e4a-4ad9-8921-182f4ca9840a",
   "metadata": {},
   "source": [
    "## Вводные данные"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da86f010-def0-478d-9c31-971b0c9ca903",
   "metadata": {},
   "source": [
    "Наша цель — тестирование способности LLM к разрешению кореферентности ([если хочется немного разобраться, что это](https://tpc.ispras.ru/wp-content/uploads/2018/11/lecture-8.pdf)) \"опросом\" модели с помощью zero-shot промптов.\n",
    "\n",
    "Примеры таких промптов можно посмотреть в [этой статье](https://aclanthology.org/2024.lrec-main.145.pdf) в приложении G (на странице 10) и в [этой статье](https://arxiv.org/pdf/2305.14489) в таблице 10 (на странице 13).\n",
    "\n",
    "Ваша цель — немного поработать за нас :)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df91d9a0-4561-4acd-b5ce-4b696e89c6f9",
   "metadata": {},
   "source": [
    "## Задача"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "928b343d-96a4-40e3-bb58-b6ee704ef812",
   "metadata": {},
   "source": [
    "### Пункт А\n",
    "\n",
    "* Возьмите размеченный на референциальные связи корпус **русскоязычных** текстов — мы предлагаем взять [RuCoCo](https://github.com/vdobrovolskii/rucoco), но вы можете взять любой.\n",
    "\n",
    "* Напишите шаблон промпта для QA-тестирования модели: инструкцию вида \"Вот тебе текст <текст>. Чему кореферентно слово *они* в предложении 2? Дай ответ в формате json\" (можно взять готовые из статей, упомянутых выше, можно немного их изменить, можно написать свои). Это может быть также вопрос в формате mutiple-choice.\n",
    "\n",
    "* Придумайте способ вставлять данные из размеченного корпуса в шаблон промпта так, чтобы можно было автоматически сравнить ответы модели с \"золотым стандартом\" (\"правильным ответом\", извлечённым из корпуса).\n",
    "\n",
    "* Напишите скрипт, позволяющий делать это автоматически для разных упоминаний и разных текстов корпуса, по сути — превратите корпус референциальных связей в массив вопросов для LLM, \"задачник с ключами в конце\")."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfd043d4-abeb-4125-a4ec-f681949e1e49",
   "metadata": {},
   "source": [
    "#### Золотой стандарт\n",
    "\n",
    "Например, в корпусе есть текст *\"Мама(1) мыла раму(2), и тут она(1) упала.\"*. Согласно разметке *она* кореферентно *мама*. Это и есть золотой станарт — идеальный ответ модели "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e70c3a-894e-4503-a484-a1177a5aff60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# можете вставить скрипт сюда"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33008987-51dc-4002-b5f1-2bb032e633a3",
   "metadata": {},
   "source": [
    "### Пункт Б"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "534a8392-3b42-4f1e-a39d-f14846b81d8e",
   "metadata": {},
   "source": [
    "Ответы LLM может быть проблематично парсить (они засоряются всякими \"Да, я с радостью решу вашу задачу\" и т. п., иногда даже если формат ответа прописан в инструкции).\n",
    "\n",
    "Возьмите несколько промптов с уже вставленными корпусными данными из пункта А (штук 50-100) и посмотрите, как модель отвечает на вопросы. \n",
    "\n",
    "Если ответы модели нуждаются в обработке, попробуйте придумать способ автоматически превращать их в строго форматированные."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e576ac95-b697-46da-af54-1deb3fa1288c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# можете вставить скрипт сюда"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c991d4f-3da6-468c-8869-4d9d05f23ef1",
   "metadata": {},
   "source": [
    "### Пункт В\n",
    "\n",
    "#### *если останется время и вдохновение"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a03b2015-b894-49e7-8217-47da98e6b34a",
   "metadata": {},
   "source": [
    "В [этой статье](https://arxiv.org/pdf/2305.14489) кроме вопросно-ответного тестирования LLM описан ещё подход, где модель просят \"расставить референциальные теги\" в тексте (пример есть на той же странице 13, под заголовком **Document Template**, и в Фигуре 1 на странице 2)\n",
    "\n",
    "Попробуйте сделать скрипт и для формирования таких промптов.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "317b6678-ba8c-4f55-8d7b-89da01c0a735",
   "metadata": {},
   "outputs": [],
   "source": [
    "# можете вставить скрипт сюда"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
